{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Qlearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji9SvkkE4dLL"
      },
      "source": [
        "#On  va reprendre l'exemple du Golois\r\n",
        "\r\n",
        "import gym\r\n",
        "import numpy as np\r\n",
        "env = gym.make('MountainCar-v0')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "## evaluate a random (uniform) policfy\r\n",
        "lr=[]#liste des récompenses\r\n",
        "ll=[]#liste des steps \r\n",
        "for i in range(100):#on lance 100 épisodes \r\n",
        "  env.reset()\r\n",
        "  done=False\r\n",
        "  rt=0#reward\r\n",
        "  el=0#combien de mouvement, de steps?\r\n",
        "  while not done:\r\n",
        "    s,r,done,_ = env.step(env.action_space.sample())#r=-1 tant qu'on a pas touché le but \r\n",
        "    print(s,r)\r\n",
        "    rt +=r#r=reward at this step, rt:accumulated reward \r\n",
        "    el +=1\r\n",
        "  lr.append(rt)\r\n",
        "  ll.append(el)\r\n",
        "print('average length of episodes %.2f (%.2f)'%(np.mean(ll), np.std(ll)))#pour calculer les moyennes \r\n",
        "print('average rewards of episodes %.2f (%.2f)'%(np.mean(lr), np.std(lr)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sUtQ-Kv8Hxv"
      },
      "source": [
        "# • domains: list of domains of the attributes\r\n",
        "#   ex: [[-1,1],[0,5]] two attributes: first has values in [-1,1], the second in [0,5]\r\n",
        "#Omar: first for abscisse and second for velocity\r\n",
        "#1tilling=1domain?\r\n",
        "# • nbBins: the number of bins of each tiling (here we assume the same number...)\r\n",
        "# • nbTiling: the number of tilings used (overlays of tilings)\r\n",
        "# • offsets: the offset of each tiling\r\n",
        "#   ex: [[0,0], [0.2, 0.4]] example for two attribute: no offset for the first tiling, second is offset by (0.2, 0.4)\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        "Tile coding is a way of representing the values of a vector of continuous variables as a large binary vector with few 1s and many 0s.\r\n",
        "The binary vector is not represented explicitly of course, but as a list of the components that are 1s. \r\n",
        "The main step is to partition, or tile, the continuous space multiple times and select one tile from each tiling, \r\n",
        "that corresponding the the vector's value. Each tile is converted (hashed down to) an element in the big binary vector, \r\n",
        "and the list of the tile (element) numbers is returned as the representation of the vector's value. \r\n",
        "It is recommended as a first way of applying online reinforcement learning methods to domains with continuous state or action variables.\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        "def genTilings(domains, nbBins, nbTilings, offsets):\r\n",
        "  tilings = []\r\n",
        "  for i in range(nbTilings):#here 2\r\n",
        "    t = []\r\n",
        "    #for each attribute\r\n",
        "    for a in range(len(domains)):#we have 2 domains as well\r\n",
        "      t.append(genTiling(domains[a], nbBins, offsets[i][a]))#1 TILLING=1LINSPACE=ENSEMBLE DE VALEURS ESPACE du nombre de bins=1 attribut\r\n",
        "    tilings.append(t)\r\n",
        "    #print(\"tilings=\",tilings)\r\n",
        "  return tilings\r\n",
        "\r\n",
        "# generate one tiling\r\n",
        "def genTiling(domain, nbBins, offset):\r\n",
        "  return np.linspace(start=domain[0], stop=domain[1], num=nbBins, endpoint=True)+offset\r\n",
        "\r\n",
        "# Given the observation, provides the tiles that are active\r\n",
        "def encode(observation, tilings):\r\n",
        "  code=[]\r\n",
        "  # for each tiling\r\n",
        "  for i in range(len(tilings)):\r\n",
        "    c=[];\r\n",
        "    # for each attribute #vitesse- position\r\n",
        "    for j in range(len(observation)):\r\n",
        "      val = np.digitize(observation[j],tilings[i][j])#np.digitize returns the number of the bins to which the value belongs to \r\n",
        "      c.append(val)\r\n",
        "    code.append(c)\r\n",
        "    #print(\"Code =\",code)\r\n",
        "  return code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "rNPE86wt82Vv",
        "outputId": "03b07f97-0f85-4e0b-846a-aaf1b14582a3"
      },
      "source": [
        "box = env.observation_space\r\n",
        "xmax = box.high[0]\r\n",
        "vmax = box.high[1]\r\n",
        "xmin = box.low[0]\r\n",
        "vmin = box.low[1]\r\n",
        "domainX = [xmin, xmax]\r\n",
        "domainY = [vmin, vmax]\r\n",
        "print(\"domaine des positions: \", domainX)\r\n",
        "print(\"domaine des vitesses:  \", domainY)\r\n",
        "#tilings\r\n",
        "nbBins = 8\r\n",
        "offsets=[]\r\n",
        "x=0\r\n",
        "y=0\r\n",
        "dx=(xmax-xmin)/(nbBins)**2\r\n",
        "dy=(vmax-vmin)/(nbBins)**2\r\n",
        "for t in range(nbBins):\r\n",
        "  x = (x+3)%nbBins\r\n",
        "  y = (y+1)%nbBins\r\n",
        "  offsets.append([x*dx,y*dy])\r\n",
        "tilings = genTilings([domainX,domainY], 8, 8, offsets)\r\n",
        "for i in range(nbBins):\r\n",
        "  print(\"tiling \", i , \": \")\r\n",
        "  for j in range(nbBins):\r\n",
        "    print('%.2f '% tilings[i][0][j],end='')\r\n",
        "  print()\r\n",
        "  for j in range(nbBins):\r\n",
        "    print('%.2f ' % tilings[i][1][j],end='')\r\n",
        "  print()\r\n",
        "\r\n",
        "Dx=(xmax-xmin)/nbBins\r\n",
        "Dy=(vmax-vmin)/nbBins\r\n",
        "for i in range(nbBins):\r\n",
        "  #plt.fill(X,Y,color=\"grey\")\r\n",
        "  #chaque surface rectangulaire grise correspond à un appel de fill\r\n",
        "  #on peut considérer ce plot comme un zoom sur la première portion des tuiles\r\n",
        "  plt.fill([offsets[i][0], offsets[i][0]+Dx, offsets[i][0]+Dx, offsets[i][0], offsets[i][0]], [offsets[i][1], offsets[i][1], offsets[i][1]+Dy, offsets[i][1]+Dy,offsets[i][1]],'green',alpha=0.1)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "domaine des positions:  [-1.2, 0.6]\n",
            "domaine des vitesses:   [-0.07, 0.07]\n",
            "tiling  0 : \n",
            "-1.12 -0.86 -0.60 -0.34 -0.09 0.17 0.43 0.68 \n",
            "-0.07 -0.05 -0.03 -0.01 0.01 0.03 0.05 0.07 \n",
            "tiling  1 : \n",
            "-1.03 -0.77 -0.52 -0.26 -0.00 0.25 0.51 0.77 \n",
            "-0.07 -0.05 -0.03 -0.01 0.01 0.03 0.05 0.07 \n",
            "tiling  2 : \n",
            "-1.17 -0.91 -0.66 -0.40 -0.14 0.11 0.37 0.63 \n",
            "-0.06 -0.04 -0.02 -0.00 0.02 0.04 0.06 0.08 \n",
            "tiling  3 : \n",
            "-1.09 -0.83 -0.57 -0.32 -0.06 0.20 0.46 0.71 \n",
            "-0.06 -0.04 -0.02 -0.00 0.02 0.04 0.06 0.08 \n",
            "tiling  4 : \n",
            "-1.00 -0.75 -0.49 -0.23 0.03 0.28 0.54 0.80 \n",
            "-0.06 -0.04 -0.02 0.00 0.02 0.04 0.06 0.08 \n",
            "tiling  5 : \n",
            "-1.14 -0.89 -0.63 -0.37 -0.12 0.14 0.40 0.66 \n",
            "-0.06 -0.04 -0.02 0.00 0.02 0.04 0.06 0.08 \n",
            "tiling  6 : \n",
            "-1.06 -0.80 -0.55 -0.29 -0.03 0.23 0.48 0.74 \n",
            "-0.05 -0.03 -0.01 0.01 0.03 0.05 0.07 0.09 \n",
            "tiling  7 : \n",
            "-1.20 -0.94 -0.69 -0.43 -0.17 0.09 0.34 0.60 \n",
            "-0.07 -0.05 -0.03 -0.01 0.01 0.03 0.05 0.07 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wTkv82-89Zs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "wFHQMBNB89tF",
        "outputId": "14c11d4c-75d8-4829-c597-a7ee36378a5d"
      },
      "source": [
        "# assumes D only\r\n",
        "def plot2DTiling(t, color):\r\n",
        "  n = len(t[0])-1\r\n",
        "  for i in range(n):\r\n",
        "    x=[t[0][i],t[0][i]]\r\n",
        "    y=[t[1][0],t[1][n]]\r\n",
        "    plt.plot(x,y,c=color,linewidth=1)\r\n",
        "    x=[t[0][0],t[0][n]]\r\n",
        "    y=[t[1][i],t[1][i]]\r\n",
        "    plt.plot(x,y,c=color,linewidth=1)\r\n",
        "    \r\n",
        "def plot2DTilings(tilings):\r\n",
        "  lc = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'olive','cyan']\r\n",
        "  for i in range(len(tilings)):\r\n",
        "    plot2DTiling(tilings[i], lc[i])\r\n",
        "    \r\n",
        "plot2DTilings(tilings)\r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3qNEy8e7k-T"
      },
      "source": [
        "def epsGreedy(tilings, w, state, epsilon):\r\n",
        "  nbActions = env.action_space.n\r\n",
        "  if np.random.rand() < epsilon:\r\n",
        "    # explore\r\n",
        "    return np.random.randint(0,high=nbActions)\r\n",
        "  else:\r\n",
        "    #exploit\r\n",
        "    #compute the Q values for each action\r\n",
        "    nbTilings = len(tilings)\r\n",
        "    q=[]\r\n",
        "    for a in range(nbActions):#on itére sur nbActions\r\n",
        "      val = 0\r\n",
        "      for t in range(nbTilings):#ensuite sur le nombre de tilings\r\n",
        "          val += w[t][state[t][0],state[t][1],a]#w représente les poids w\r\n",
        "          #on somme toutes les récompense pour un épisode\r\n",
        "      q.append(val)\r\n",
        "    return np.argmax(q)#on renvoie l'indice de l'action correspondant au maximum de la valeur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUAgNi9L7tn-"
      },
      "source": [
        "def Memory_filling(tilings,nbr_episodes,alpha,epsilon,gamma):\r\n",
        "  nbActions = env.action_space.n\r\n",
        "  nbTilings = len(tilings)\r\n",
        "  nbAttributes = len(tilings[0])\r\n",
        "  nbBins = len(tilings[0][0])\r\n",
        "  numActions = env.action_space\r\n",
        "  print('space with ', nbAttributes, ' attributes and ', nbActions, ' actions')\r\n",
        "  print('encoded with ', nbTilings, ' tilings with ', nbBins, ' each')\r\n",
        "  episodeLength=[]\r\n",
        "  episodeReward=[]\r\n",
        "  D=[]#Memory\r\n",
        "  V_t=[]\r\n",
        "  A_t=[]\r\n",
        "  A_t_p=[]\r\n",
        "  D_t_p=[]\r\n",
        "  # initialise Q tables\r\n",
        "  w=[]\r\n",
        "  for i in range(nbTilings):\r\n",
        "    w.append(np.zeros((nbBins, nbBins, nbActions)))\r\n",
        "\r\n",
        "  #let's learn\r\n",
        "  for it in range(nbr_episodes):#Répéter éternellement pour chaque épisode\r\n",
        "    obs = env.reset()\r\n",
        "    s1 = encode(obs, tilings)\r\n",
        "    a1 = epsGreedy(tilings, w, s1, epsilon)#on choisit une action avec epsilon-greedy\r\n",
        "    done=False\r\n",
        "    rt=0\r\n",
        "    el=0\r\n",
        "    while (not done):#Répète pour chaque étape de l'épisode\r\n",
        "      obs, r, done, info = env.step(a1)\r\n",
        "      s2 = encode(obs, tilings)\r\n",
        "      a2 = epsGreedy(tilings, w, s2, epsilon)\r\n",
        "      # q updates\r\n",
        "      q1 = 0\r\n",
        "      q2 = 0\r\n",
        "      # compute estimates Q(s1,a1) and Q(s2,a2)\r\n",
        "      # q(s,a) = sum the weights of the active cells.\r\n",
        "      for t in range(nbTilings):\r\n",
        "        q1 += w[t][s1[t][0],s1[t][1],a1]#a1 est l'ancienne action\r\n",
        "        q2 += w[t][s2[t][0],s2[t][1],a2]#a2 est la nouvelle action\r\n",
        "      # weight update\r\n",
        "      for t in range(nbTilings):\r\n",
        "        w[t][s1[t][0],s1[t][1],a1] = w[t][s1[t][0],s1[t][1],a1] + alpha*(r + gamma * q2 - q1)#q2 is equivalent to v and q1 to v chapeau\r\n",
        "      # update states and actions\r\n",
        "      s1_temp=s1\r\n",
        "      a1_temp=a1\r\n",
        "      s1 = s2\r\n",
        "      a1 = a2#la nouvelle action devient l'ancienne \r\n",
        "      el += 1\r\n",
        "      rt += r\r\n",
        "      transition=[np.array(s1_temp),a1_temp,rt,np.array(s2)]\r\n",
        "      D.append(np.array(s1_temp))\r\n",
        "      A_t.append(a1_temp)\r\n",
        "      A_t_p.append(a1)\r\n",
        "      D_t_p.append(np.array(s1))\r\n",
        "      V_t.append(-r)\r\n",
        "      \r\n",
        "    episodeLength.append(el)\r\n",
        "    episodeReward.append(rt)\r\n",
        "  return w, episodeLength, episodeReward,np.array(D),np.array(A_t),np.array(V_t),np.array(D_t_p),np.array(A_t_p)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sU-WJCJdIUH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq5qrTI7R4tR",
        "outputId": "0206c103-5ccf-47e2-e6a3-ef2779fb338d"
      },
      "source": [
        "w,episodeLength,episodeReward,my_memory,policies,values,my_memory_p,policies_p=Memory_filling(tilings,100,0.01,0.1,0.99)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNPhrXwSmvBN",
        "outputId": "bae6d0eb-41cc-44e6-8612-a96e2e2ca8b0"
      },
      "source": [
        "print(values)\r\n",
        "print(policies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. ... 1. 1. 1.]\n",
            "[2 0 2 ... 1 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "096eNVAKX6F4",
        "outputId": "7049cb53-e640-4bba-98da-2e4bae901b3b"
      },
      "source": [
        "my_memory=np.array(my_memory)\r\n",
        "print(my_memory.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19977, 8, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94f80XrcM1q7"
      },
      "source": [
        "def pick_random_transition(batch_size):\r\n",
        "  w_test,episodeLength_test,episodeReward_test,my_memory_test,policies_test,values_test,my_memory_test_p,policies_test_p=Memory_filling(tilings,1000,0.01,0.1,0.99)\r\n",
        "\r\n",
        "  indice = np.random.choice(len(my_memory_test), batch_size, replace=False) \r\n",
        "  transition_aleatoire=[]\r\n",
        "  policies=[]\r\n",
        "  values=[]\r\n",
        "  policies_p=[]\r\n",
        "  transition_aleatoire_p=[]\r\n",
        "\r\n",
        "  print(len(indice))\r\n",
        "  for idx in range(len(indice)):\r\n",
        "    transition_aleatoire.append(my_memory_test[indice[idx]])\r\n",
        "    policies.append(policies_test[indice[idx]])\r\n",
        "    values.append(values_test[indice[idx]])\r\n",
        "    #policies_p.append(policies_test_p[indice[idx]])\r\n",
        "    transition_aleatoire_p.append(my_memory_test_p[indice[idx]])\r\n",
        "\r\n",
        "\r\n",
        "  return np.array(transition_aleatoire),np.array(policies),np.array(values),np.array(transition_aleatoire_p)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bhWUotxiV9i"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow.keras as keras\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras import layers \r\n",
        "from tensorflow.keras import regularizers\r\n",
        "\r\n",
        "nb_actions = env.action_space.n\r\n",
        "epochs = 200\r\n",
        "batch = 60\r\n",
        "#*****\r\n",
        "alpha=0.01\r\n",
        "epsilon=0.1\r\n",
        "gamma=0.99\r\n",
        "filters=3\r\n",
        "\r\n",
        "def NN_qlearning(input_data):\r\n",
        "  N =input_data.shape[0]\r\n",
        "  input_data = input_data.astype ('float32')\r\n",
        "  print(input_data.shape)#add\r\n",
        "  policy = np.random.randint(nb_actions, size=(batch,))#choisi une politique aléatoire entre 1 et 3\r\n",
        "  policy = keras.utils.to_categorical (policy)\r\n",
        "  value = np.random.randint(2, size=(batch,))#gagné ou perdu\r\n",
        "  value = value.astype ('float32')\r\n",
        "  input = keras.Input(shape=input_data.reshape((input_data.shape[0],input_data.shape[1],input_data.shape[2],1)).shape[1:],batch_size=batch, name='data')\r\n",
        "  print(\"shape input=\",input.shape)\r\n",
        "  for i in range (4):#pour model résiduel\r\n",
        "      x = layers.ReLU()(input)\r\n",
        "      x=layers.Dropout(0.10)(x)\r\n",
        "      x = layers.BatchNormalization()(x)\r\n",
        "\r\n",
        "  \r\n",
        "  value_head = layers.Dense(30, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(x)\r\n",
        "  value_head=layers.Dropout(0.10)(value_head)\r\n",
        "  value_head = layers.Flatten()(value_head)\r\n",
        "  value_head = layers.Dense(nb_actions, activation='linear', name='value', kernel_regularizer=regularizers.l2(0.0008))(value_head)\r\n",
        "\r\n",
        "  model = keras.Model(inputs=input, outputs= value_head)\r\n",
        "  model.summary ()\r\n",
        "  model.compile(optimizer=keras.optimizers.SGD(lr=0.012, momentum=0.95),\r\n",
        "                loss={ 'value': 'binary_crossentropy'},\r\n",
        "                loss_weights={ 'value' : 1.0},\r\n",
        "                metrics={ 'value': 'mse'})\r\n",
        "  \r\n",
        "  return model\r\n",
        "\r\n",
        "def train_and_test(model,my_target_model):\r\n",
        " \r\n",
        "  for i in range (1, epochs + 1):\r\n",
        "      print ('epoch ' + str (i))\r\n",
        "      input_data,policies,values,input_data_p=pick_random_transition(1)\r\n",
        "      value=values#valeur d'entraineemntzs\r\n",
        "      value = value.astype ('float32')\r\n",
        "      old_values=my_model(input_data)\r\n",
        "      a_p=tf.argmax(old_values[0]).numpy()\r\n",
        "      target_values=value+gamma*my_target_model(input_data_p)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "      #policy = tf.convert_to_tensor(policy)\r\n",
        "\r\n",
        "\r\n",
        "      target_value=tf.convert_to_tensor(target_values)\r\n",
        "      history = model.fit(input_data,\r\n",
        "                          { 'value': target_value}, \r\n",
        "                          epochs=1, batch_size=batch)\r\n",
        "      \r\n",
        "    \r\n",
        "     \r\n",
        "      '''\r\n",
        "      if (i % 10 == 0):\r\n",
        "          input_data,policies,values,input_data_p=pick_random_transition(batch)\r\n",
        "          #input data=St,policies=At,values=rt,policies_p=At+1,input_data_p=St+1\r\n",
        "          policy=keras.utils.to_categorical(policies)#valeurs d'entraiement\r\n",
        "          value=values#valeur d'entraineemntzs\r\n",
        "          value = value.astype ('float32')\r\n",
        "\r\n",
        "          policy = tf.convert_to_tensor(policy)\r\n",
        "          value=tf.convert_to_tensor(value)\r\n",
        "          val = model.evaluate (input_data,\r\n",
        "                                [policy, value], verbose = 0, batch_size=batch)#mse sur les données de validations (su rles données qui n'ont jamais été)\r\n",
        "          print (\"val =\", val)\r\n",
        "\r\n",
        "          model.save ('test.h5')\r\n",
        "          '''\r\n",
        "  return model\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K6NUU2IehOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e136f8a1-a7fd-49f9-87f0-afffd428f22f"
      },
      "source": [
        "my_model= NN_qlearning(input_data)\r\n",
        "target_model=NN_qlearning(input_data)\r\n",
        "train_and_test(my_model,target_model)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 8, 2)\n",
            "shape input= (60, 8, 2, 1)\n",
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "data (InputLayer)            [(60, 8, 2, 1)]           0         \n",
            "_________________________________________________________________\n",
            "re_lu_99 (ReLU)              (60, 8, 2, 1)             0         \n",
            "_________________________________________________________________\n",
            "dropout_123 (Dropout)        (60, 8, 2, 1)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_99 (Batc (60, 8, 2, 1)             4         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (60, 8, 2, 30)            60        \n",
            "_________________________________________________________________\n",
            "dropout_124 (Dropout)        (60, 8, 2, 30)            0         \n",
            "_________________________________________________________________\n",
            "flatten_36 (Flatten)         (60, 480)                 0         \n",
            "_________________________________________________________________\n",
            "value (Dense)                (60, 3)                   1443      \n",
            "=================================================================\n",
            "Total params: 1,507\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n",
            "(1, 8, 2)\n",
            "shape input= (60, 8, 2, 1)\n",
            "Model: \"model_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "data (InputLayer)            [(60, 8, 2, 1)]           0         \n",
            "_________________________________________________________________\n",
            "re_lu_103 (ReLU)             (60, 8, 2, 1)             0         \n",
            "_________________________________________________________________\n",
            "dropout_128 (Dropout)        (60, 8, 2, 1)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_103 (Bat (60, 8, 2, 1)             4         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (60, 8, 2, 30)            60        \n",
            "_________________________________________________________________\n",
            "dropout_129 (Dropout)        (60, 8, 2, 30)            0         \n",
            "_________________________________________________________________\n",
            "flatten_37 (Flatten)         (60, 480)                 0         \n",
            "_________________________________________________________________\n",
            "value (Dense)                (60, 3)                   1443      \n",
            "=================================================================\n",
            "Total params: 1,507\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n",
            "epoch 1\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 10.9807 - mse: 2.3378\n",
            "epoch 2\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8786 - mse: 2.0233\n",
            "epoch 3\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -4.0472 - mse: 1.4308\n",
            "epoch 4\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -9.0354 - mse: 0.6215\n",
            "epoch 5\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -13.8381 - mse: 1.0561\n",
            "epoch 6\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -13.5338 - mse: 2.3838\n",
            "epoch 7\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -10.4168 - mse: 12.4934\n",
            "epoch 8\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4557 - mse: 26.7699\n",
            "epoch 9\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4576 - mse: 36.5586\n",
            "epoch 10\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -4.9794 - mse: 35.6870\n",
            "epoch 11\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -7.2316 - mse: 67.6270\n",
            "epoch 12\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -14.4337 - mse: 53.6698\n",
            "epoch 13\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -4.3827 - mse: 98.4556\n",
            "epoch 14\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -8.6334 - mse: 122.0901\n",
            "epoch 15\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -16.9734 - mse: 83.8029\n",
            "epoch 16\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n",
            "1\n",
            "1/1 [==============================] - 0s 4ms/step - loss: -13.3039 - mse: 158.3476\n",
            "epoch 17\n",
            "space with  2  attributes and  3  actions\n",
            "encoded with  8  tilings with  8  each\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ-lrN3AKdt6",
        "outputId": "1d802264-1ecd-4e75-eb40-b8fc4bfd904a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19977, 8, 2)\n",
            "shape input= (60, 8, 2, 1)\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "data (InputLayer)            [(60, 8, 2, 1)]           0         \n",
            "_________________________________________________________________\n",
            "re_lu_71 (ReLU)              (60, 8, 2, 1)             0         \n",
            "_________________________________________________________________\n",
            "dropout_88 (Dropout)         (60, 8, 2, 1)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_71 (Batc (60, 8, 2, 1)             4         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (60, 8, 2, 30)            60        \n",
            "_________________________________________________________________\n",
            "dropout_89 (Dropout)         (60, 8, 2, 30)            0         \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (60, 480)                 0         \n",
            "_________________________________________________________________\n",
            "value (Dense)                (60, 3)                   1443      \n",
            "=================================================================\n",
            "Total params: 1,507\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}