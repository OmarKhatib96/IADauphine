{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_RL_PD (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqDAHSx_XFh9"
      },
      "source": [
        "# Value Iteration & Policy Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeCbCndGXPr_"
      },
      "source": [
        "On va utiliser l'exemple du monde grille simple. \n",
        "\n",
        "![Grid World](https://www.lamsade.dauphine.fr/~airiau/Teaching/M2-IASDapp-RL/gridworld.png)\n",
        "\n",
        "\n",
        "\n",
        "On va numéroter les états comme suit:\n",
        "\n",
        "| 7 | 8 | 9 | 10 |\n",
        "|---|---|----|---|\n",
        "| **4** |  - | **5** | **6**  |\n",
        "| **0** | **1** | **2** | **3**  |\n",
        "\n",
        "Les états finaux sont donc les états 6 et 10.\n",
        "\n",
        "On a 4 actions disponibles, on les encode de la façon suivante:\n",
        "* $\\uparrow$: 0 \n",
        "* $\\leftarrow$ : 1\n",
        "* $\\downarrow$: 2\n",
        "* $\\rightarrow$ : 3\n",
        "\n",
        "Ci-dessous, on a entré pour vous la matrice de transition $T$ et la matrice de récompense $R$. Ainsi $T[s_1,a,s_2]$ donne la probabilité d'atteindre l'état $s_2$ en ayant pris l'action $a$ dans l'état $s_1$ et $R[s,a]$ donne la récompense immédiate reçue après avoir pris l'action $a$ dans l'état $s$.\n",
        "\n",
        "Vous pouvez facilement changer la pénalité pour avancer d'une case en changeant la valeur de la variable `penalty` ci-dessous.\n",
        "\n",
        "Ce n'est peut-être pas la manière la plus élégante, mais cela suffira pour l'exercice!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGGujRrVXEe3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "l=0.8\n",
        "s = 0.1\n",
        "v_win = 1\n",
        "v_lose = -1\n",
        "\n",
        "T = np.zeros((11, 4, 11))\n",
        "#UP\n",
        "T[0,0,:]=[s, s, 0, 0, l, 0, 0, 0, 0, 0, 0 ] \n",
        "T[1,0,:]=[s, l, s, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[2,0,:]=[0, s, 0, s, 0, l, 0, 0, 0, 0, 0 ]\n",
        "T[3,0,:]=[0, 0, s, s, 0, 0, l, 0, 0, 0, 0 ]\n",
        "T[4,0,:]=[0, 0, 0, 0, 2*s, 0, 0, l, 0, 0, 0 ]\n",
        "T[5,0,:]=[0, 0, 0, 0, 0, s, s, 0, 0, l, 0 ]\n",
        "T[6,0,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[7,0,:]=[0, 0, 0, 0, 0, 0, 0, s+l, s, 0, 0 ]\n",
        "T[8,0,:]=[0, 0, 0, 0, 0, 0, 0, s, l, s, 0 ]\n",
        "T[9,0,:]=[0, 0, 0, 0, 0, 0, 0, 0, s, l, s ]\n",
        "T[10,0,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n",
        "#LEFT\n",
        "T[0,1,:]=[s+l, 0, 0, 0, s, 0, 0, 0, 0, 0, 0 ] \n",
        "T[1,1,:]=[l, 2*s, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[2,1,:]=[0, l, s, 0, 0, s, 0, 0, 0, 0, 0 ]\n",
        "T[3,1,:]=[0, 0, l, s, 0, 0, s, 0, 0, 0, 0 ]\n",
        "T[4,1,:]=[s, 0, 0, 0, l, 0, 0, s, 0, 0, 0 ]\n",
        "T[5,1,:]=[0, 0, s, 0, 0, l, 0, 0, 0, s, 0 ]\n",
        "T[6,1,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[7,1,:]=[0, 0, 0, 0, s, 0, 0, s+l, 0, 0, 0 ]\n",
        "T[8,1,:]=[0, 0, 0, 0, 0, 0, 0, l, 2*s, 0, 0 ]\n",
        "T[9,1,:]=[0, 0, 0, 0, 0, s, 0, 0, l, s, 0 ]\n",
        "T[10,1,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n",
        "# DOWN\n",
        "T[0,2,:]=[s+l, s, 0, 0, 0, 0, 0, 0, 0, 0, 0 ] \n",
        "T[1,2,:]=[s, l, s, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[2,2,:]=[0, s, l, s, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[3,2,:]=[0, 0, s, l+s, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[4,2,:]=[l, 0, 0, 0, 2*s, 0, 0, 0, 0, 0, 0 ]\n",
        "T[5,2,:]=[0, 0, l, 0, 0, s, s, 0, 0, 0, 0 ]\n",
        "T[6,2,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[7,2,:]=[0, 0, 0, 0, l, 0, 0, s, s, 0, 0 ]\n",
        "T[8,2,:]=[0, 0, 0, 0, 0, 0, 0, s, l, s, 0 ]\n",
        "T[9,2,:]=[0, 0, 0, 0, 0, 0, 0, 0, s, l, s ]\n",
        "T[10,2,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n",
        "#RIGHT\n",
        "T[0,3,:]=[s, l, 0, 0, s, 0, 0, 0, 0, 0, 0 ] \n",
        "T[1,3,:]=[0, 2*s, l, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[2,3,:]=[0, 0, s, l, 0, s, 0, 0, 0, 0, 0 ]\n",
        "T[3,3,:]=[0, 0, 0, s+l, 0, 0, s, 0, 0, 0, 0 ]\n",
        "T[4,3,:]=[s, 0, 0, 0, l, 0, 0, s, 0, 0, 0 ]\n",
        "T[5,3,:]=[0, 0, s, 0, 0, 0, l, 0, 0, s, 0 ]\n",
        "T[6,3,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
        "T[7,3,:]=[0, 0, 0, 0, s, 0, 0, s, l, 0, 0 ]\n",
        "T[8,3,:]=[0, 0, 0, 0, 0, 0, 0, 0, 2*s, l, 0 ]\n",
        "T[9,3,:]=[0, 0, 0, 0, 0, s, 0, 0, 0, s, l ]\n",
        "T[10,3,:]=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ]\n",
        "\n",
        "penalty= 0.00;\n",
        "R = penalty*np.ones((11,4))\n",
        "R[10,:]= np.ones(4)*v_win\n",
        "R[6,:]= np.ones(4)*v_lose\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10zkeVqGtFpO"
      },
      "source": [
        "## Value Iteration\n",
        "Implémentez l'algorithme d'itération sur les valeurs. Pour ce faire, implémentez une fonction qui prend en paramètre:\n",
        "* $\\epsilon$ le paramètre pour le test d'arrêt (dans un premier temps, vous pouvez remplacer ce paramètre par un nombre d'itération maximal, comme dans l'appel ci-dessou)\n",
        "* $\\gamma$ le taux d'escompte (i.e. un facteur qui dévalue une récomponse obtenue dans le future)\n",
        "* $T$ la matrice de transition\n",
        "* $R$ la matrice de récompense\n",
        "\n",
        "La méthode retourne le vecteur $v: S \\rightarrow {\\mathbb R}$ qui associe à chaque état la valeur optimale de cet état.\n",
        "\n",
        "La fonction $printV$ ci-dessous affichera les valeurs de $v$ pour le problème du gridworld.\n",
        "\n",
        "Vous pourrez ainsi tester si vous retrouvez les valeurs de l'exemple montré en cours. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7vc1R3DcODC"
      },
      "source": [
        "#Value Iteration algorithm\r\n",
        "#initialisation des matrices des états\r\n",
        "\r\n",
        "def valueIteration(nbr_iterations,gamma, T,R):\r\n",
        "  S=[0,1,2,3,4,5,6,7,8,9,10]\r\n",
        "  S=np.array(S)\r\n",
        "  S=S.reshape((1,11))\r\n",
        "  V=np.zeros(S.shape)\r\n",
        "  print(V.shape)\r\n",
        "  gamma=0.9\r\n",
        "  epsilon=0.0001\r\n",
        "  delta=2#init\r\n",
        "  while delta>=epsilon:\r\n",
        "    delta=0\r\n",
        "    for state in S:\r\n",
        "      v=V[0][state]\r\n",
        "      print(\"v shape is\",v.shape)\r\n",
        "      a_max=np.argmax(R,axis=1)\r\n",
        "      V[0][state]=np.amax(R,axis=1)+gamma*np.sum(T[state,a_max,:],axis=0)\r\n",
        "      delta=max(delta,abs(v-V[0][state])[0])\r\n",
        "\r\n",
        "    return V[0].tolist()\r\n",
        "\r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2iqnIKhlg2k"
      },
      "source": [
        "def printV(v):\n",
        "  print('| {:03.2f} | {:03.2f} | {:03.2f} | {:03.2f} |'.format(v[7], v[8], v[9], v[10]))\n",
        "  print('| {:03.2f} | ---- | {:03.2f} | {:03.1f} |'.format(v[4], v[5], v[6]))\n",
        "  print('| {:03.2f} | {:03.2f} | {:03.2f} | {:03.2f} |'.format(v[0], v[1], v[2], v[3]))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai_RjaGylVnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d4207d-4536-4037-ca58-82c2bea9a05f"
      },
      "source": [
        "w = valueIteration(100, 0.9, T, R)\n",
        "printV(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 11)\n",
            "v shape is (11,)\n",
            "| 1.62 | 0.90 | 1.53 | 1.09 |\n",
            "| 0.90 | ---- | 0.81 | -0.2 |\n",
            "| 0.18 | 0.90 | 0.18 | 0.18 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvibNWnFzAQO"
      },
      "source": [
        "# plot the best policy given the value function v:\n",
        "# i.e. plot the best action for each state given the value function v.\n",
        "\n",
        "def plotBestPolicy(v, gamma):\n",
        "  bestV=np.zeros(11)\n",
        "  bestA=np.zeros(11)\n",
        "  fig, ax = plt.subplots()\n",
        "  # policy extraction\n",
        "  for s1 in range(11):\n",
        "    val=[]\n",
        "    for a in range(4):\n",
        "      va=0\n",
        "      for s2 in range(11):\n",
        "        va += T[s1,a,s2]*v[s2]\n",
        "      val= val+[ R[s1,a]+gamma*va ]\n",
        "    bestV[s1]=np.max(val)\n",
        "    bestA[s1]=np.argmax(val)\n",
        "\n",
        "    matV= np.array( [[bestV[7], bestV[8], bestV[9], bestV[10]],\n",
        "                    [bestV[4],   -1 , bestV[5], bestV[6]],\n",
        "                    [bestV[0], bestV[1], bestV[2], bestV[3]]]\n",
        "                    )\n",
        "    matA = np.array([\n",
        "                    [bestA[7], bestA[8], bestA[9], -1],\n",
        "                    [bestA[4],   -1 , bestA[5], -1],\n",
        "                    [bestA[0], bestA[1], bestA[2], bestA[3]]])\n",
        "\n",
        "    im = ax.imshow(matV)\n",
        "\n",
        "\n",
        "  for i in range(matV.shape[0]):\n",
        "      for j in range(matV.shape[1]):\n",
        "          if matA[i][j]==-1:\n",
        "              arrow = ''\n",
        "          elif matA[i, j] == 0:\n",
        "              arrow = '^'\n",
        "          elif matA[i, j] == 1:\n",
        "              arrow = '<'\n",
        "          elif matA[i, j] == 2:\n",
        "              arrow = 'v'\n",
        "          elif matA[i, j] == 3:\n",
        "              arrow = '>'\n",
        "          text = ax.text(j, i, arrow, ha = \"center\", va = \"center\",\n",
        "                         color = \"black\")\n",
        "            \n",
        "  cbar = ax.figure.colorbar(im, ax = ax)\n",
        "    \n",
        "  fig.tight_layout()\n",
        "  plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AMDenr44UCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1ec41579-755f-4f8f-bcdd-c1f07fd5e5ee"
      },
      "source": [
        "plotBestPolicy(V, 0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOUAug-46kNB"
      },
      "source": [
        "Vous pouvez modifier la matrice de récompense pour observer les différentes politiques optimales vues en cours. Peut-être en avons nous oublié?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Gh1rWu6SLI"
      },
      "source": [
        "## Policy Iteration\n",
        "\n",
        "Implémentez l'algorithme d'itération sur les politiques. Pour débuger, vous pouvez regarder dessiner la politique avec les fonctions ci-dessus (pour voir la fonction de valeur et/ou la politique associée).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWL-jnqxCUIP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}