{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDBNvj00l6eW"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbQqFbxbmEhD",
        "outputId": "1db34962-fefd-493f-f63e-8be2ffa57d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):#prend en paramètre une séquence de nombre et la transforme en liste de liste de nombre shape:(nombre d'exemple,10000)\n",
        "    results = np.zeros((len(sequences), dimension))#len(sequence)=nombre d'exemples\n",
        "    print(dimension)\n",
        "    print(len(sequences[0]))\n",
        "    for i in range (len (sequences)):\n",
        "        for j in range (len (sequences [i])):\n",
        "            results [i] [sequences [i] [j]] = 1.#on prend l'indice de cet entier et l'indice de cet entier dans le vecteur\n",
        "    return results#ok\n",
        "\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "one_hot_train_labels = to_categorical(train_labels) \n",
        "one_hot_test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(train_labels)\n",
        "\n",
        "y_train = np.asarray(one_hot_train_labels).astype('float32')\n",
        "print(train_labels)\n",
        "print(train_labels.shape)\n",
        "y_test = np.asarray(one_hot_test_labels).astype('float32')\n",
        "     \n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(.45, input_shape=(10000,)))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "x_val = x_train[:1000] \n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = one_hot_train_labels[:1000] \n",
        "partial_y_train = one_hot_train_labels[1000:]\n",
        "\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))\n",
        "import matplotlib.pyplot as plt \n",
        "loss = history.history['loss'] \n",
        "val_loss = history.history['val_loss'] \n",
        "epochs = range(1, len(loss) + 1) \n",
        "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss') \n",
        "plt.title('Training and validation loss') \n",
        "plt.xlabel('Epochs') \n",
        "plt.ylabel('Loss') \n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''' \n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]\n",
        "\n",
        "\n",
        "history = model.fit (partial_x_train, partial_y_train, epochs=20,batch_size=20, validation_data=(x_val, y_val))\n",
        "\n",
        "\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "\n",
        "\n",
        "loss_values = history_dict['loss']\n",
        "\n",
        "\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss with reg and dropout')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss with reg and dropout')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.clf() #Clears the figure\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "'''\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "87\n",
            "10000\n",
            "145\n",
            "[ 3  4  3 ... 25  3 25]\n",
            "[ 3  4  3 ... 25  3 25]\n",
            "(8982,)\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 2.8582 - accuracy: 0.4359 - val_loss: 1.8809 - val_accuracy: 0.6370\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.7254 - accuracy: 0.6453 - val_loss: 1.4175 - val_accuracy: 0.6850\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 1.3592 - accuracy: 0.7072 - val_loss: 1.2405 - val_accuracy: 0.7120\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.1595 - accuracy: 0.7413 - val_loss: 1.1485 - val_accuracy: 0.7350\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.0043 - accuracy: 0.7701 - val_loss: 1.0840 - val_accuracy: 0.7550\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.8820 - accuracy: 0.7987 - val_loss: 1.0341 - val_accuracy: 0.7600\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.7628 - accuracy: 0.8239 - val_loss: 0.9841 - val_accuracy: 0.7840\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.6665 - accuracy: 0.8482 - val_loss: 0.9629 - val_accuracy: 0.7860\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.6029 - accuracy: 0.8617 - val_loss: 0.9483 - val_accuracy: 0.7990\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.5281 - accuracy: 0.8809 - val_loss: 0.9287 - val_accuracy: 0.8110\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.4766 - accuracy: 0.8893 - val_loss: 0.9283 - val_accuracy: 0.8110\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.4295 - accuracy: 0.9042 - val_loss: 0.9097 - val_accuracy: 0.8240\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.3870 - accuracy: 0.9116 - val_loss: 0.9456 - val_accuracy: 0.8100\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.3622 - accuracy: 0.9163 - val_loss: 0.9552 - val_accuracy: 0.8140\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.3173 - accuracy: 0.9270 - val_loss: 0.9745 - val_accuracy: 0.8150\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.2941 - accuracy: 0.9267 - val_loss: 0.9684 - val_accuracy: 0.8130\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.2753 - accuracy: 0.9361 - val_loss: 0.9707 - val_accuracy: 0.8140\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.2491 - accuracy: 0.9414 - val_loss: 1.0223 - val_accuracy: 0.8030\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.2391 - accuracy: 0.9391 - val_loss: 1.0326 - val_accuracy: 0.8100\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.2190 - accuracy: 0.9468 - val_loss: 1.0074 - val_accuracy: 0.8180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" \\nx_val = x_train[:10000]\\npartial_x_train = x_train[10000:]\\n\\n\\ny_val = y_train[:10000]\\npartial_y_train = y_train[10000:]\\n\\n\\nhistory = model.fit (partial_x_train, partial_y_train, epochs=20,batch_size=20, validation_data=(x_val, y_val))\\n\\n\\n \\nimport matplotlib.pyplot as plt\\nhistory_dict = history.history\\n\\n\\nloss_values = history_dict['loss']\\n\\n\\nval_loss_values = history_dict['val_loss']\\n\\n\\n\\n\\n\\nepochs = range(1, len(loss_values) + 1)\\nplt.plot(epochs, loss_values, 'bo', label='Training loss with reg and dropout')\\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss with reg and dropout')\\n\\n\\n\\n\\nplt.title('Training and validation loss')\\nplt.xlabel('Epochs')\\nplt.ylabel('Loss')\\nplt.legend()\\nplt.show()\\nplt.clf() #Clears the figure\\nacc = history_dict['acc']\\nval_acc = history_dict['val_acc']\\nplt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\\nplt.title('Training and validation accuracy')\\nplt.xlabel('Epochs')\\nplt.ylabel('Accuracy')\\nplt.legend()\\nplt.show()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YwQIWNo2Wof",
        "outputId": "0c0f5d5c-0c3a-40a9-f1ef-34ffb5519a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " #sklearn.metrics.classification_report(y_test, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
        "y_pred = model.predict_classes(x_test)\n",
        "print(classification_report(Y_test, y_pred))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-41bbea8dcbb7>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.50      0.63        12\n",
            "           1       0.64      0.81      0.71       105\n",
            "           2       0.76      0.65      0.70        20\n",
            "           3       0.90      0.94      0.92       813\n",
            "           4       0.79      0.88      0.84       474\n",
            "           5       1.00      0.20      0.33         5\n",
            "           6       0.92      0.86      0.89        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.74      0.66      0.69        38\n",
            "           9       0.87      0.80      0.83        25\n",
            "          10       0.90      0.90      0.90        30\n",
            "          11       0.66      0.70      0.68        83\n",
            "          12       0.50      0.15      0.24        13\n",
            "          13       0.64      0.57      0.60        37\n",
            "          14       1.00      0.50      0.67         2\n",
            "          15       0.50      0.11      0.18         9\n",
            "          16       0.67      0.79      0.73        99\n",
            "          17       1.00      0.17      0.29        12\n",
            "          18       0.81      0.65      0.72        20\n",
            "          19       0.63      0.71      0.67       133\n",
            "          20       0.54      0.51      0.53        70\n",
            "          21       0.77      0.74      0.75        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.50      0.25      0.33        12\n",
            "          24       0.67      0.32      0.43        19\n",
            "          25       0.83      0.65      0.73        31\n",
            "          26       0.83      0.62      0.71         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.67      0.20      0.31        10\n",
            "          29       0.40      0.50      0.44         4\n",
            "          30       0.83      0.42      0.56        12\n",
            "          31       0.75      0.46      0.57        13\n",
            "          32       1.00      0.50      0.67        10\n",
            "          33       1.00      0.80      0.89         5\n",
            "          34       0.80      0.57      0.67         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.71      0.45      0.56        11\n",
            "          37       0.00      0.00      0.00         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.67      0.20      0.31        10\n",
            "          41       0.50      0.12      0.20         8\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.75      1.00      0.86         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.79      2246\n",
            "   macro avg       0.70      0.48      0.53      2246\n",
            "weighted avg       0.79      0.79      0.78      2246\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}